{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd93145e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3149da118075480aaa846fa0aab9e25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='dataset.csv', description='Input file:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b7edb2f9424e65a3f29eb4a21ffb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Modo:', options=('rows', 'dynamic'), value='rows')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa8e6dcd23342e4bfd3297b6ff737ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, description='Max MB:', max=200, min=10, step=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608f23d3126548d7b2e5f6a1b65e4359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Formato:', options=('csv', 'parquet'), value='csv')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9db5ece6ad84b58907eefe4ba698f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='splits', description='Output dir:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd3f4d3f17540a3aad07ee2ba5c1810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='part', description='Base name:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808e46c40ad4425bb80af70ca3564f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Dividir Dataset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CHardyE-DK\\miniconda3\\envs\\.venvConda\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CHardyE-DK\\miniconda3\\envs\\.venvConda\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1140\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyarrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36mon_run_clicked\u001b[39m\u001b[34m(b)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_run_clicked\u001b[39m(b):\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mrun_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path_text\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mrun_split\u001b[39m\u001b[34m(input_path)\u001b[39m\n\u001b[32m     76\u001b[39m     df = pd.read_csv(input_path)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m input_path.endswith(\u001b[33m\"\u001b[39m\u001b[33m.parquet\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFormato no soportado. Usa CSV o Parquet.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CHardyE-DK\\miniconda3\\envs\\.venvConda\\Lib\\site-packages\\pandas\\io\\parquet.py:653\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_parquet\u001b[39m(\n\u001b[32m    502\u001b[39m     path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     **kwargs,\n\u001b[32m    511\u001b[39m ) -> DataFrame:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[33;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[32m    514\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    650\u001b[39m \u001b[33;03m    1    4    9\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m    656\u001b[39m         msg = (\n\u001b[32m    657\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe argument \u001b[39m\u001b[33m'\u001b[39m\u001b[33muse_nullable_dtypes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will be removed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    658\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min a future version.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    659\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CHardyE-DK\\miniconda3\\envs\\.venvConda\\Lib\\site-packages\\pandas\\io\\parquet.py:79\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPyArrowImpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FastParquetImpl()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CHardyE-DK\\miniconda3\\envs\\.venvConda\\Lib\\site-packages\\pandas\\io\\parquet.py:164\u001b[39m, in \u001b[36mPyArrowImpl.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyarrow is required for parquet support.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CHardyE-DK\\miniconda3\\envs\\.venvConda\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def split_by_rows(df, max_mb=100, output_dir=\"splits\", base_name=\"part\", fmt=\"csv\"):\n",
    "    total_bytes = df.memory_usage(deep=True).sum()\n",
    "    total_mb = total_bytes / (1024**2)\n",
    "    rows_per_chunk = math.floor(len(df) * (max_mb / total_mb))\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    num_chunks = math.ceil(len(df) / rows_per_chunk)\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start = i * rows_per_chunk\n",
    "        end = (i + 1) * rows_per_chunk\n",
    "        chunk = df.iloc[start:end]\n",
    "\n",
    "        filename = os.path.join(output_dir, f\"{base_name}_rows_{i+1}.{fmt}\")\n",
    "        if fmt == \"csv\":\n",
    "            chunk.to_csv(filename, index=False)\n",
    "        elif fmt == \"parquet\":\n",
    "            chunk.to_parquet(filename, index=False)\n",
    "        print(f\"[rows] Guardado {filename} con {len(chunk)} filas\")\n",
    "\n",
    "\n",
    "def split_dynamic(df, max_mb=100, output_dir=\"splits\", base_name=\"part\", fmt=\"csv\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    start = 0\n",
    "    part = 1\n",
    "    while start < len(df):\n",
    "        end = start + 10000\n",
    "        while end <= len(df):\n",
    "            chunk = df.iloc[start:end]\n",
    "            filename = os.path.join(output_dir, f\"{base_name}_dyn_{part}.{fmt}\")\n",
    "            if fmt == \"csv\":\n",
    "                chunk.to_csv(filename, index=False)\n",
    "            elif fmt == \"parquet\":\n",
    "                chunk.to_parquet(filename, index=False)\n",
    "\n",
    "            size_mb = os.path.getsize(filename) / (1024**2)\n",
    "            if size_mb > max_mb:\n",
    "                end = end - 1000 if end - 1000 > start else start + 1\n",
    "                chunk = df.iloc[start:end]\n",
    "                if fmt == \"csv\":\n",
    "                    chunk.to_csv(filename, index=False)\n",
    "                elif fmt == \"parquet\":\n",
    "                    chunk.to_parquet(filename, index=False)\n",
    "                size_mb = os.path.getsize(filename) / (1024**2)\n",
    "                print(f\"[dyn] Guardado {filename} con {len(chunk)} filas ({size_mb:.2f} MB)\")\n",
    "                start = end\n",
    "                part += 1\n",
    "                break\n",
    "            else:\n",
    "                end += 10000\n",
    "        else:\n",
    "            chunk = df.iloc[start:]\n",
    "            filename = os.path.join(output_dir, f\"{base_name}_dyn_{part}.{fmt}\")\n",
    "            if fmt == \"csv\":\n",
    "                chunk.to_csv(filename, index=False)\n",
    "            elif fmt == \"parquet\":\n",
    "                chunk.to_parquet(filename, index=False)\n",
    "            size_mb = os.path.getsize(filename) / (1024**2)\n",
    "            print(f\"[dyn] Guardado {filename} con {len(chunk)} filas ({size_mb:.2f} MB)\")\n",
    "            break\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Widget interactivo\n",
    "# ============================\n",
    "\n",
    "def run_split(input_path):\n",
    "    # Cargar dataset\n",
    "    if input_path.endswith(\".csv\"):\n",
    "        df = pd.read_csv(input_path)\n",
    "    elif input_path.endswith(\".parquet\"):\n",
    "        df = pd.read_parquet(input_path, engine=\"pyarrow\")\n",
    "    else:\n",
    "        print(\"Formato no soportado. Usa CSV o Parquet.\")\n",
    "        return\n",
    "\n",
    "    mode = mode_selector.value\n",
    "    max_mb = mb_slider.value\n",
    "    fmt = format_selector.value\n",
    "    output_dir = output_dir_text.value\n",
    "    base_name = base_name_text.value\n",
    "\n",
    "    if mode == \"rows\":\n",
    "        split_by_rows(df, max_mb=max_mb, output_dir=output_dir, base_name=base_name, fmt=fmt)\n",
    "    else:\n",
    "        split_dynamic(df, max_mb=max_mb, output_dir=output_dir, base_name=base_name, fmt=fmt)\n",
    "\n",
    "\n",
    "# Widgets\n",
    "mode_selector = widgets.Dropdown(options=[\"rows\", \"dynamic\"], value=\"rows\", description=\"Modo:\")\n",
    "mb_slider = widgets.IntSlider(value=100, min=10, max=200, step=10, description=\"Max MB:\")\n",
    "format_selector = widgets.Dropdown(options=[\"csv\", \"parquet\"], value=\"csv\", description=\"Formato:\")\n",
    "output_dir_text = widgets.Text(value=\"splits\", description=\"Output dir:\")\n",
    "base_name_text = widgets.Text(value=\"part\", description=\"Base name:\")\n",
    "input_path_text = widgets.Text(value=\"dataset.csv\", description=\"Input file:\")\n",
    "\n",
    "run_button = widgets.Button(description=\"Dividir Dataset\", button_style=\"success\")\n",
    "\n",
    "def on_run_clicked(b):\n",
    "    run_split(input_path_text.value)\n",
    "\n",
    "run_button.on_click(on_run_clicked)\n",
    "\n",
    "# Mostrar interfaz\n",
    "display(input_path_text, mode_selector, mb_slider, format_selector, output_dir_text, base_name_text, run_button)\n",
    "\n",
    "# D:\\CHardyE-Projects\\Python\\DataAnalitics\\DataAnalitics2025\\NYC_Taxi_Lab\\data\\raw\\yellow_tripdata_2025-01.parquet\n",
    "# D:\\CHardyE-Projects\\Python\\DataAnalitics\\DataAnalitics2025\\NYC_Taxi_Lab\\data\\splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c8c69e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyarrow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(pyarrow.__version__)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyarrow'"
     ]
    }
   ],
   "source": [
    "import pyarrow\n",
    "print(pyarrow.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venvConda)",
   "language": "python",
   "name": ".venvconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
